## 1) Commenta le principali fallacie dei sistemi distribuiti.

Le **fallacie del calcolo distribuito** sono convinzioni errate comunemente fatte dagli sviluppatori quando progettano sistemi distribuiti. Queste assunzioni possono portare a implementazioni fragili, inefficaci o addirittura fallimentari. Di seguito una panoramica delle principali:

---

### 1. **La rete √® affidabile**

√à un errore presumere che le connessioni tra i nodi siano sempre attive e stabili. In realt√†:

- Le reti possono cadere temporaneamente.
- I pacchetti possono essere persi o duplicati.
- I timeout possono generare ambiguit√† (la richiesta √® arrivata o no?).

‚úÖ **Cosa fare:** Implementare retry, timeout intelligenti, logging e fallback. Usare l'iniezione delle dipendenze aiuta a testare meglio i componenti che dipendono da servizi remoti.

---

### 2. **La latenza √® zero**

Presupporre che le comunicazioni tra componenti siano istantanee √® sbagliato:

- La latenza pu√≤ essere significativa (specialmente su Internet).
- Le differenze di latenza impattano le prestazioni e la UX.

üìä Esempio: 1s CPU = 100 anni in latenza Internet (in scala normalizzata).

```
| Process                             | Duration | Normalized |
|-------------------------------------|----------|------------|
| 1 CPU cycle                         | 0.3ns    | 1s         |
| L1 cache access                     | 1ns      | 3s         |
| L2 cache access                     | 3ns      | 9s         |
| L3 cache access                     | 13ns     | 43s        |
| DRAM access (from CPU)              | 120ns    | 6min       |
| SSD I/O                             | 0.1ms    | 4days      |
| HDD I/O                             | 1-10ms   | 1-12months |
| Internet: San Francisco to New York | 40ms     | 4years     |
| Internet: San Francisco to London   | 80ms     | 8years     |
| Internet: San Francisco to Sydney   | 130ms    | 13years    |
| TCP retransmit                      | 1s       | 100years   |
| Container reboot                    | 4s       | 400years   |
```

‚úÖ **Cosa fare:** Progettare le applicazioni per essere tolleranti alla latenza, ad esempio con circuit breaker, cache locali e logica asincrona.

---

### 3. **La larghezza di banda √® infinita**

Si tende a pensare che si possano inviare e ricevere dati illimitatamente. In realt√†:

- La banda √® limitata fisicamente e logicamente.
- Serializzazione, congestione di rete e overhead riducono la banda effettiva.

‚úÖ **Cosa fare:** Minimizzare il traffico, evitare payload pesanti, usare compressione e streaming se possibile.

---

### 4. **La rete √® sicura**

Assumere che i dati viaggino in modo sicuro √® pericoloso:

- I dati possono essere intercettati o manipolati.
- Accessi non autorizzati possono verificarsi.

‚úÖ **Cosa fare:** Usare TLS, autenticazione robusta, gestione dei secret, auditing e sicurezza end-to-end.

---

### 5. **La topologia non cambia**

Molti credono che la configurazione della rete sia statica, ma:

- I nodi possono essere aggiunti, rimossi o spostati.
- Le IP cambiano, i DNS si aggiornano, i container vengono riavviati.

‚úÖ **Cosa fare:** Usare service discovery, DNS dinamici, e orchestratori (es. Kubernetes) per adattarsi ai cambiamenti.

---

### 6. **C'√® un solo amministratore**

Spesso si crede che ci sia una sola persona a gestire tutto. Ma nei team distribuiti:

- Pi√π sviluppatori e team interagiscono con il sistema.
- Il coordinamento √® essenziale per evitare conflitti e disallineamenti.

‚úÖ **Cosa fare:** Automatizzare i deployment, usare controllo di versione per la configurazione, definire processi condivisi.

---

### 7. **Il costo del trasporto √® zero**

Trasferire dati ha sempre un costo:

- Latenza, serializzazione, CPU per encoding/decoding.
- Costo economico nel cloud (data egress, API calls, etc.).

‚úÖ **Cosa fare:** Limitare i dati trasferiti, ottimizzare la serializzazione, monitorare i costi nei servizi cloud.

---

### 8. **La rete √® omogenea**

√à errato pensare che tutti i nodi siano uguali. In realt√†:

- Tecnologie diverse (Java, Python, Go, Rust‚Ä¶).
- Sistemi operativi, database e formati di dati eterogenei.

‚úÖ **Cosa fare:** Usare protocolli standard (REST, gRPC), formati comuni (JSON, Protobuf), e strumenti di integrazione robusti.

---

### Conclusione

Le **fallacie del calcolo distribuito** sono pericolose perch√© portano a sottovalutare la complessit√† della rete, della comunicazione e della cooperazione tra sistemi. Riconoscerle e progettare tenendone conto √® essenziale per costruire **sistemi distribuiti resilienti, scalabili e manutenibili**.

## 2) Come contribuisce l'iniezione delle dipendenze alla diffusione delle fallacie dei sistemi distribuiti?

L‚Äô**iniezione delle dipendenze (Dependency Injection)** √® una tecnica utile per aumentare la modularit√† e testabilit√† del codice, ma **pu√≤ contribuire alla diffusione delle fallacie del calcolo distribuito** se utilizzata in modo inconsapevole nei contesti distribuiti. Ecco perch√©:

1. **Maschera la natura remota delle chiamate**

Quando un servizio remoto viene iniettato come una normale dipendenza (ad esempio un client HTTP), il codice **sembra locale**, ma **non lo √®**.

```java
public class OrderService {
    private final PaymentService paymentService; // potrebbe sembrare locale

    public OrderService(PaymentService paymentService) {
        this.paymentService = paymentService;
    }

    public void processOrder(Order order) {
        paymentService.charge(order); // in realt√† √® una chiamata remota
    }
}
```

üëâ **Fallacia alimentata**: *‚ÄúLa rete √® affidabile‚Äù* o *‚ÄúLa latenza √® zero‚Äù*

Poich√© la chiamata sembra una normale invocazione Java, gli sviluppatori dimenticano di gestire timeout, errori di rete, ritenti, fallback ecc.

---

2. **Favorisce l‚Äôastrazione eccessiva**

L‚Äôiniezione di un client remoto tramite interfacce astratte pu√≤ far perdere consapevolezza che ci si sta collegando a un servizio remoto, potenzialmente instabile o con prestazioni variabili.

üëâ **Fallacia alimentata**: *‚ÄúIl costo di trasporto √® zero‚Äù*

L‚Äôinvocazione di metodi remoti pu√≤ sembrare trascurabile, ma in realt√† ogni chiamata comporta serializzazione, latenza, costi di rete, possibili ritrasmissioni.

---

3. **Rende difficile distinguere i confini di sistema**

Con l‚Äôiniezione automatica di dipendenze remote (es. tramite Spring o CDI), i confini tra componenti locali e distribuiti si offuscano. Questo pu√≤ portare a una **scarsa progettazione della comunicazione tra servizi**, che √® critica in un‚Äôarchitettura distribuita.

üëâ **Fallacia alimentata**: *‚ÄúLa rete √® omogenea‚Äù*

Non tutti i servizi parlano allo stesso modo o si comportano nello stesso modo. Trattarli come ‚Äúblack box‚Äù interscambiabili pu√≤ essere rischioso.

---

4. **Difficolt√† nel trattamento degli errori specifici**

Un client iniettato pu√≤ nascondere eccezioni specifiche del contesto di rete (es. `HttpTimeoutException`, `ConnectException`), inducendo lo sviluppatore a trattarle come eccezioni normali o generiche.

üëâ **Fallacia alimentata**: *‚ÄúLa rete √® sicura‚Äù* o *‚ÄúLa topologia non cambia‚Äù*

Se non si distinguono i casi in cui il servizio √® irraggiungibile da quelli in cui restituisce un errore, si possono prendere decisioni sbagliate lato business o sicurezza.

**In sintesi: *non dimenticare mai che una dipendenza remota non √® una dipendenza locale*.**

## 3) Quali sono i quattro stili di comunicazione fondamentali nei sistemi distribuiti?

I **quattro stili di comunicazione fondamentali nei sistemi distribuiti** derivano dalla combinazione di due assi principali:

1. **Tipo di relazione** tra client e servizio:
    - **Uno-a-Uno**
    - **Uno-a-Molti**
2. **Modalit√† temporale** della comunicazione:
    - **Sincrona**
    - **Asincrona**

**Richiesta/Risposta (Uno-a-Uno, Sincrono):** In questo stile classico di interazione, un client invia una richiesta a un servizio e attende una risposta diretta. L‚Äôaspettativa √® di avere una risposta tempestiva, il che pu√≤ portare a un accoppiamento stretto tra il client e il servizio. Questo modello √® comune nelle applicazioni web tradizionali e nelle API dove √® richiesto un feedback immediato. -> ma √® bloccante

**Richiesta/Risposta Asincrona (Uno-a-Uno, Asincrono):** In questa interazione, un client invia una richiesta ma non attende una risposta immediata. Invece, pu√≤ continuare a elaborare altre attivit√†. Il servizio risponder√† eventualmente, ma il client non si blocca mentre attende. Questo modello aiuta a migliorare l‚Äôesperienza utente prevenendo freeze o ritardi dell‚Äôinterfaccia utente.

**Publish/Subscribe (Uno-a-Molti, Asincrono):** Questo modello di interazione consente a un client di pubblicare messaggi su un argomento o canale che possono essere consumati da pi√π servizi. I servizi interessati si iscrivono a questi messaggi, che possono essere elaborati in modo indipendente dal pubblicatore.

Questo disaccoppia i client dai servizi, consentendo un‚Äôarchitettura pi√π flessibile.

**Publish/Subscribe Asincrone (Uno-a-Molti, Asincrono):** In questa variazione, un client pubblica un messaggio di richiesta a pi√π servizi e attende risposte per un periodo di tempo specificato. Questo consente al client di ricevere input da vari servizi senza bloccare la propria operazione, aumentando l‚Äôefficienza.

| Tipo di Comunicazione | Relazione | Temporalit√† | Uso Tipico |
| --- | --- | --- | --- |
| Richiesta/Risposta | Uno-a-Uno | Sincrono | API REST, servizi web |
| Richiesta/Risposta Asincrona | Uno-a-Uno | Asincrono | Code di messaggi, elaborazioni batch |
| Publish/Subscribe | Uno-a-Molti | Asincrono | Event-driven architecture, notifiche |
| Pub/Sub con Risposte | Uno-a-Molti | Asincrono | Aggregazione di dati da pi√π fonti |

## 4) Quali sono i limiti della comunicazione sincrona?

La **comunicazione sincrona** √® un modello in cui un componente (tipicamente un client) invia una richiesta e attende una risposta prima di poter proseguire. Sebbene sia semplice da implementare (come nel caso di REST), presenta **diversi limiti strutturali**, specialmente in ambienti distribuiti e ad alta concorrenza, come quelli basati su microservizi.

### üî∑**Accoppiamento Temporale**

**Il concetto di accoppiamento temporale** si verifica quando i componenti o i servizi devono essere disponibili e reattivi nello stesso momento per funzionare correttamente. ‚áí *Una delle due piaghe irrisolvibili nella comunicazione sincrona.*

Questo accade spesso nei modelli di comunicazione sincrona, un componente deve attendere che un altro elabori una richiesta prima di procedere. Nei casi in cui una catena di pi√π servizi deve comunicare, **la latenza accumulata pu√≤ degradare significativamente le prestazioni**. **[non risolvibile con approcci sincroni!]**

- **Definizione:** Il client e il server devono essere attivi nello stesso momento.
- **Problema:** Se il server √® lento o non risponde, il client √® bloccato in attesa.
- **Conseguenza:** Aumenta la latenza percepita e pu√≤ causare timeout.
- **Esempio:** Un client che chiama una catena di servizi (es. A ‚Üí B ‚Üí C) si blocca se uno dei servizi √® lento o non disponibile.

### üî∑ **Accoppiamento Spaziale**

Il concetto di **accoppiamento spaziale**  si riferisce  al grado di dipendenza tra diversi componenti o servizi in un sistema in un dato momento.
Un alto grado di accoppiamento spaziale significa che i componenti sono strettamente connessi, richiedendo una conoscenza diretta dell'esistenza, delle interfacce o delle posizioni reciproche. Ci√≤ pu√≤ portare a una minore flessibilit√† e a una maggiore complessit√† di manutenzione. ‚áí La modifica di un componente comporta la modifica di tutti i componenti da esso dipendenti

- **Definizione:** I componenti devono conoscere esattamente la posizione (es. URL, porta) e l‚Äôinterfaccia degli altri.
- **Problema:** Cambiamenti a un servizio impongono modifiche a tutti i componenti che lo utilizzano.
- **Esempio:** Un `OrderService` che chiama direttamente `http://payment-service:8080` √® rigidamente accoppiato.

### üî∑ **Accoppiamento API**

**Accoppiamento API** si riferisce al grado di dipendenza tra un client e un‚ÄôAPI.

Un'API altamente accoppiata significa che le modifiche nell'API possono facilmente rompere il client, mentre un'API a basso accoppiamento fornisce maggiore flessibilit√† e resilienza ai cambiamenti.

- **Definizione:** Il client √® strettamente legato alla struttura dell‚ÄôAPI.
- **Problema:** Qualsiasi modifica ai payload (es. aggiunta di campi) pu√≤ rompere la compatibilit√†.
- **Esempio:** Modificare la classe `Payment` aggiungendo un campo `currency` pu√≤ causare errori se il client non √® aggiornato.

### üî∑ **Over-fetching**

**Over-fetching:** si verifica quando **un'API restituisce pi√π dati di quanto il client necessiti effettivamente, portando a un utilizzo inefficiente della banda e a un tempo di elaborazione aumentato**. Questo avviene tipicamente nelle API REST con strutture di risposta fisse, dove un client non pu√≤ specificare esattamente quali campi richiede.

*Scenario*: Un client desidera solo il titolo e l'autore di un libro, ma l'API restituisce l'intero oggetto libro, inclusi campi non necessari come ISBN, descrizione, editore, ecc.

- **Definizione:** Il client riceve **pi√π dati** di quelli richiesti.
- **Problema:** Utilizzo inefficiente di rete e maggiore latenza.
- **Esempio:** Un client vuole solo `title` e `author`, ma l‚ÄôAPI REST restituisce l‚Äôintero oggetto `Book` (inclusi `isbn`, `description`, ecc.).

### üî∑ **Under-fetching (Chattiness)**

**Under-fetching (noto anche come chattiness):** si verifica quando **un client richiede dati da un'API ma non riceve tutte le informazioni necessarie in una singola risposta.** Di conseguenza, il client deve effettuare ulteriori richieste per recuperare i dati mancanti, portando a inefficienze e a una latenza aumentata.

*Scenario*: L'endpoint /books restituisce un modello semplificato per i libri. Se il client ha bisogno anche dell'editore, deve effettuare richieste aggiuntive per recuperare i dettagli dell'editore come: GET /books/{title}

- **Definizione:** Il client non riceve **tutti i dati necessari** in una singola risposta.
- **Problema:** Deve fare pi√π chiamate, aumentando la latenza e il carico.
- **Esempio:** Recupero dei dettagli del libro seguito da chiamate separate per l‚Äôeditore e i commenti.

### üî∑**Esaurimento del Pool di Thread sul Client**

I client che attendono una risposta dal server consumano risorse di sistema (thread, memoria), il che pu√≤ essere problematico in ambienti ad alta concorrenza. **[non risolvibile con approcci sincroni!]**

*Scenario* : Un client interroga l'endpoint /books 100 volte al secondo. Ogni richiesta richiede in media 1 secondo per essere soddisfatta. In qualsiasi momento, il **client** ha circa 100 thread nello stato di attesa (in attesa della risposta del server). Dato che ogni thread richiede 1 MB di RAM, cosa succede se il servizio libri smette di rispondere per 10 secondi? Il client avr√† bisogno di 1 GB di RAM solo per gestirli!

- **Definizione:** Ogni richiesta sincrona occupa un thread finch√© non riceve risposta.
- **Problema:** In scenari ad alta concorrenza, i thread si esauriscono causando degrado delle performance.
- **Esempio:** Se 100 richieste REST durano 1 secondo, sono necessari 100 thread in attesa. Se il server rallenta, il consumo di RAM esplode.

### üî∑ **Serializzazione Verbosa**

**La serializzazione** √® il processo di conversione di strutture dati o oggetti in un formato che pu√≤ essere facilmente trasmesso o archiviato. Questo formato √® spesso uno stream di byte o testo, che pu√≤ essere successivamente deserializzato (convertito nuovamente) nella struttura dati o nell'oggetto originale. Questo concetto pu√≤ portare ad una maggiore latenza nella risoluzione della richiesta.

- **Definizione:** REST utilizza solitamente JSON o XML.
- **Problema:** Sono formati **testuali**, verbosi, lenti da serializzare e deserializzare.
- **Conseguenza:** Aumenta la latenza della comunicazione.

## 5) Come Protobuf e GraphQL mitigano gli svantaggi di REST?

Rest soffre di tutti i limiti delle comunicazioni sincrone

**Come GraphQL Risolve le Limitazioni di REST**:

- **Accoppiamento API**: A differenza di REST, dove diverse risorse sono esposte attraverso molteplici endpoint, GraphQL opera attraverso un unico endpoint per tutte le query, semplificando la struttura dell'API. Diversamente da REST, che spesso richiede il versionamento per gestire i cambiamenti, lo schema flessibile di GraphQL permette modifiche non invalidanti, come l'aggiunta di nuovi campi senza impattare i client esistenti.
- **Over-fetching e under-fetching (verbosit√†)**: GraphQL permette ai client di richiedere solo i campi di cui hanno bisogno, risolvendo il problema di REST del ritorno di dati non necessari (over-fetching) o della necessit√† di effettuare multiple richieste per ottenere i dati necessari (under-fetching).
- **Serializzazione**: Il numero ridotto di richieste e risposte (grazie all'utilizzo di un singolo endpoint flessibile) riduce anche il carico complessivo della serializzazione.

**Come gRPC Risolve le Limitazioni di REST**:

- **Serializzazione**: gRPC utilizza Protocol Buffers (Protobuf), un formato binario compatto, per la serializzazione dei dati invece di JSON o XML (comunemente utilizzati nelle API REST). I formati binari sono molto pi√π efficienti in termini di dimensioni e velocit√† perch√© occupano meno spazio e sono pi√π rapidi da serializzare e deserializzare.
- **Accoppiamento API**: gRPC definisce contratti API rigorosi, garantendo una tipizzazione forte e riducendo il rischio di modifiche invalidanti. Con il supporto integrato per la compatibilit√† sia retroattiva che futura, l'evoluzione delle API √® pi√π fluida rispetto a REST, dove le modifiche nei payload JSON o nelle specifiche possono pi√π facilmente introdurre incompatibilit√†.
- **Over-fetching**: gRPC riduce l'over-fetching attraverso una serializzazione binaria efficiente.
- **Under-fetching (chattiness)**: gRPC minimizza i viaggi multipli sfruttando il multiplexing di [HTTP/2](https://www.cloudflare.com/learning/performance/http2-vs-http1.1/), permettendo una comunicazione efficiente

**Limitazioni di GraphQL**:

- **Complessit√† nell'ottimizzazione delle query**: Mentre GraphQL offre flessibilit√† ai client, pone anche maggiore responsabilit√† sul server per ottimizzare le query. Se non gestite correttamente, le query complesse o profondamente annidate possono portare a colli di bottiglia nelle prestazioni lato server.
- **Sfide nel caching**: Il caching in GraphQL √® pi√π complesso rispetto a REST, poich√© le query possono essere dinamiche e granulari. Le API REST possono sfruttare pi√π facilmente il caching basato su HTTP (basato sugli endpoint), mentre GraphQL richiede strategie di caching pi√π sofisticate.
- **Overhead degli schema**: Il sovraccarico della gestione degli schema e dei resolver potrebbe non giustificare i benefici in tutti i casi d'uso.

**Limitazioni di gRPC**:

- **Complessit√†**: Protobuf introduce una maggiore complessit√† in termini di definizioni degli schemi e generazione del codice.
- **Supporto Browser**: Mentre gRPC √® eccellente per la comunicazione backend e tra servizi, non √® ben supportato negli ambienti browser, limitando il suo utilizzo per le applicazioni frontend.
- **Tipizzazione Rigida**: Mentre la tipizzazione rigida garantisce robustezza, introduce anche rigidit√†, poich√© le modifiche all'API richiedono una gestione attenta dei contratti Protobuf.

## 6) Quali sono i trade-offs tra l'utilizzo della messaggistica sincrona e asincrona in un sistema distribuito?

| Aspetto | Comunicazione **Sincrona** | Comunicazione **Asincrona** |
| --- | --- | --- |
| **Definizione** | Il client invia una richiesta e **attende la risposta** del servizio remoto. | Il client invia un messaggio e **non aspetta** una risposta immediata. La comunicazione avviene in modo decoupled. |
| **Tecnologie comuni** | REST, gRPC, HTTP | RabbitMQ, Kafka, SQS, NATS, Event Streams |
| **Semplicit√†** | Pi√π semplice da implementare e testare | Richiede progettazione pi√π attenta: messaggi, eventi, gestione errori |
| **Accoppiamento** | **Forte accoppiamento**: i servizi devono essere attivi contemporaneamente | **Basso accoppiamento**: il producer non ha bisogno che il consumer sia disponibile |
| **Prestazioni** | **Maggiore latenza percepita** per l‚Äôutente finale | **Migliore scalabilit√†** e throughput, minor tempo bloccante per i produttori |
| **Affidabilit√†** | Pi√π fragile: se il servizio remoto √® gi√π, la chiamata fallisce | Pi√π resiliente: i messaggi possono essere accodati e processati quando possibile |
| **Debug/Tracing** | Pi√π facile il tracing end-to-end (es. HTTP 500) | Pi√π difficile il tracing: serve correlare eventi e gestire la delivery asincrona |
| **Consistenza** | Pi√π semplice mantenere consistenza immediata | Consistenza eventuale: pi√π difficile coordinare aggiornamenti distribuiti |

‚úÖ **Quando usare la comunicazione sincrona**:

- Quando √® richiesta una **risposta immediata** (es. autenticazione utente)
- Per **chiamate semplici e dirette** tra pochi servizi
- Quando la **consistenza immediata** √® prioritaria

‚úÖ **Quando preferire l'asincrona**:

- Per gestire **flussi ad alto carico**
- Per favorire **disaccoppiamento e resilienza**
- In architetture **event-driven** o **a microservizi**

## 7) Quali sono i trade-offs tra gli stili di comunicazione asincrona basati su broker e senza broker?

---

### üîÅ Con **Broker (Message Broker)**

Esempi: RabbitMQ, Kafka, ActiveMQ, Amazon SQS

| Vantaggi | Svantaggi |
| --- | --- |
| ‚úÖ Gestione affidabile dei messaggi (persistenza, retry, dead-letter) | ‚ùå Introduce una **dipendenza centrale** (il broker) |
| ‚úÖ Decoupling forte: producer e consumer non si conoscono | ‚ùå Pi√π complesso da monitorare e gestire |
| ‚úÖ Supporta pattern come fanout, topic, delayed delivery | ‚ùå Rischio di **single point of failure** (risolvibile con clustering) |

### üîó Senza **Broker (Brokerless, peer-to-peer)**

Esempi: ZeroMQ, WebSocket P2P, HTTP polling/event push, NATS (in alcune modalit√†)

| Vantaggi | Svantaggi |
| --- | --- |
| ‚úÖ **Minore latenza**: meno hop nella rete | ‚ùå Meno affidabilit√† (nessuna persistenza integrata) |
| ‚úÖ Pi√π leggero, ideale per sistemi embedded o edge | ‚ùå Il producer deve conoscere e contattare direttamente i consumer |
| ‚úÖ Pi√π semplice in scenari con pochi nodi | ‚ùå Scalabilit√† e resilienza inferiori rispetto ai broker |

---

## 8) Cosa sono gli scambi di messaggi e le code, e come supportano la comunicazione nelle architetture a microservizi?

Nelle **architetture a microservizi**, la comunicazione tra servizi pu√≤ avvenire in modalit√† **asincrona** utilizzando un sistema di **messaggistica**. Due componenti fondamentali di questi sistemi sono:

- **Exchange (Scambio di messaggi)**
- **Queue (Coda di messaggi)**

Sono concetti chiave di **AMQP** (Advanced Message Queuing Protocol), utilizzato da sistemi come RabbitMQ.

### üîÅ Exchange (Scambio)

Un **Exchange** √® il componente che **riceve i messaggi dai produttori** (producer) e decide **come inoltrarli alle code** (queue), in base a **regole di instradamento** (routing).

üìå L‚ÄôExchange **non memorizza i messaggi**, ma **li distribuisce** alle code in base al tipo di exchange e alla *routing key* del messaggio.

### Tipi di exchange principali:

| Tipo di Exchange | Comportamento | Use case |
| --- | --- | --- |
| **Direct** | Inoltra il messaggio alla coda che ha **esattamente** la stessa `routing key`. | Log di sistema per livelli (es. ERROR, INFO). |
| **Fanout** | Inoltra **a tutte le code collegate** (ignora la routing key). | Notifiche broadcast (es. invio email/SMS a tutti). |
| **Topic** | Inoltra a code che corrispondono a un **pattern wildcard** nella routing key. | Eventi categorizzati, es. `ordine.spedito`, `utente.creato`. |
| **Headers** | Instrada in base a **metadati del messaggio** (header), non alla routing key. | Routing complesso (es. per area geografica, priorit√†). |

Le code sono un componente fondamentale che memorizza i messaggi. Agiscono come intermediari tra i produttori di messaggi e i consumatori.¬† ‚Üí I messaggi inviati dalle applicazioni vengono instradati attraverso gli exchange e quindi finiscono in coda, in attesa di essere elaborati dalle applicazioni consumer.

Gli attributi chiave delle code in RabbitMQ, ad esempio, includono:

- **Archiviazione:** le code archiviano i messaggi fino a quando non vengono elaborati o utilizzati dalle applicazioni.
- **Durabilit√†**: le code possono essere durevoli, il che significa che sopravvivono al riavvio del broker. La durabilit√† garantisce che i messaggi non vadano persi anche in caso di riavvio di RabbitMQ.
- **Ordine dei messaggi:** per impostazione predefinita, RabbitMQ mantiene l'ordine dei messaggi all'interno di una coda (FIFO - First-In, First-Out).
- **Propriet√† configurabili:** le code hanno propriet√† configurabili come la lunghezza massima, i livelli di priorit√† massimi, il TTL (Time-To-Live) del messaggio, ecc., che consentono l'ottimizzazione per soddisfare requisiti specifici.

### üß© Come supportano le architetture a microservizi?

| Beneficio | Descrizione |
| --- | --- |
| ‚úÖ **Disaccoppiamento** | Il produttore di un messaggio **non deve conoscere** il destinatario. Il messaggio √® pubblicato su un exchange e recapitato alla queue giusta. |
| ‚úÖ **Scalabilit√†** | Pi√π consumer possono essere associati a una coda per elaborare messaggi in parallelo. |
| ‚úÖ **Resilienza** | Se un servizio √® momentaneamente non disponibile, la queue **mantiene i messaggi** fino al suo ritorno. |
| ‚úÖ **Elasticit√†** | Possibilit√† di aggiungere nuovi microservizi ascoltando le stesse code senza modificare i producer. |
| ‚úÖ **Event-driven architecture** | I microservizi reagiscono agli eventi pubblicati nel sistema: esempio, un servizio di fatturazione reagisce all‚Äôevento `ordine.pagato`. |

## 9) Come si possono scalare i consumer RabbitMQ in un'applicazione Spring Boot per gestire grandi volumi di messaggi? Descrivi le differenze tra gruppi di consumer, partizioni e routing dei messaggi.

RabbitMQ √® un broker di messaggi open-source ampiamente utilizzato che facilita la comunicazione tra diverse parti di un sistema distribuito. Permette alle applicazioni di inviare e ricevere messaggi attraverso un sistema di messaggistica robusto e flessibile basato sul ***Protocollo Avanzato di Accodamento Messaggi (AMQP).*** RabbitMQ supporta vari modelli di messaggistica, rendendolo adatto a diverse casistiche.

In un sistema distribuito basato su RabbitMQ, **scalare i consumer** significa **aumentare la capacit√† dell'applicazione di consumare e processare messaggi in parallelo**, soprattutto in scenari ad alto volume.

In **Spring Boot con Spring AMQP**, √® possibile scalare in diversi modi:

---

### üîπ 1. **Avviare pi√π istanze dell‚Äôapplicazione**

- Ogni istanza agisce come un **consumer** connesso alla stessa **queue**.
- RabbitMQ distribuisce automaticamente i messaggi in modo **round-robin** tra i consumer **concorrenti** (di default uno per istanza).
- ‚úÖ Vantaggio: semplice da configurare, adatto al **bilanciamento del carico**.
- ‚ö†Ô∏è Limite: tutti i consumer leggono dalla **stessa queue** ‚Üí nessuna partizione logica.

```yaml
spring:
  rabbitmq:
    listener:
      simple:
        concurrency: 5      # numero minimo di consumer
        max-concurrency: 10 # numero massimo (auto-scaling)
```

---

### üîπ 2. **Configurare pi√π consumer in una singola istanza**

- √à possibile gestire **pi√π thread consumer** all‚Äôinterno della stessa JVM (Spring Boot app).
- Usando `SimpleMessageListenerContainer`, si pu√≤ definire la **concorrenza locale** (thread multipli).

```java
@Bean
public SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory(ConnectionFactory connectionFactory) {
    SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory();
    factory.setConnectionFactory(connectionFactory);
    factory.setConcurrentConsumers(5);
    factory.setMaxConcurrentConsumers(10);
    return factory;
}
```

***Componenti Chiave di RabbitMQ***

- **Produttore**: L‚Äôapplicazione che invia messaggi al broker.
- **Consumatore:** L‚Äôapplicazione che riceve messaggi da una coda.
- **Coda:** Un buffer che memorizza i messaggi fino a quando non vengono consumati.
- **Scambio:** Un meccanismo di instradamento che determina come i messaggi vengono distribuiti alle code.
- **Collegamento:** Un legame tra uno scambio e una coda che definisce le regole di instradamento per i messaggi.
- **Chiave di Routing:** L‚Äôattributo di messaggio che viene preso in considerazione dallo scambio quando si decide come instradare un messaggio.

![image](https://github.com/user-attachments/assets/9e013b1c-cda7-4746-8844-194ed3f7f0fb)


Gli Exchange e le code vanno configurate in modo da rispettare i requisiti del sistema.

### ‚öôÔ∏è **Differenze tra gruppi di consumer, partizioni e routing dei messaggi**

üî∏ **Consumer Group** (concetto pi√π legato a Kafka)

- In RabbitMQ, non esistono formalmente **consumer group** come in Kafka.
- Tuttavia, si pu√≤ **simulare** un comportamento simile assegnando **code diverse a gruppi di consumer** o usando **routing keys dinamici**.
- Ogni consumer riceve messaggi solo da **una queue**. Se pi√π consumer ascoltano la **stessa queue**, condividono il carico.

**üî∏ Partizioni (concetto di Kafka, assente in RabbitMQ)**

- RabbitMQ **non supporta partizioni native**. Ogni queue √® un‚Äôunit√† di consumo singola.
- Si pu√≤ **simulare la partizione** creando **pi√π code** e usando il routing per distribuire i messaggi.
- Esempio:
    - `queue.1`, `queue.2`, `queue.3`
    - Routing key: `event.1`, `event.2`, `event.3`

üî∏ **Routing dei messaggi (Exchange)**

- Il **meccanismo principale per scalare logicamente i consumer in RabbitMQ**.
- Puoi usare **exchange + routing key** per smistare i messaggi su **pi√π code**, ognuna consumata da un gruppo dedicato.

| Tipo Exchange | Routing Strategy | Use Case |
| --- | --- | --- |
| **Direct** | Match esatto con routing key | Log per livello (INFO, ERROR) |
| **Topic** | Pattern-based (`*.user`) | Eventi categorizzati (user.signup, user.login) |
| **Fanout** | Nessuna routing key (broadcast) | Notifiche push a tutti i consumer |
| **Headers** | Match su metadati (es. `x-match=all`) | Filtraggio avanzato multi-condizione |

---

Per scalare i consumer RabbitMQ in Spring Boot:

- Usa **pi√π consumer concorrenti** (thread o istanze)
- Configura **routing + exchange** per dividere logicamente il carico
- Tieni presente che RabbitMQ **non ha partizioni n√© consumer group** come Kafka
- Puoi comunque **simulare la segmentazione** tramite exchange, routing key e code multiple

## 10) Cosa sono i DTO e qual √® il loro ruolo nella comunicazione distribuita?

Un **DTO (Data Transfer Object)** √® un **design pattern** usato per **trasferire dati tra processi**, livelli o moduli di un'applicazione, in particolare in **contesti distribuiti**, come microservizi o API RESTful.

### Obiettivo principale:

> Trasportare dati in modo semplificato, efficiente e disaccoppiato, evitando di esporre direttamente entit√† interne (es. oggetti di dominio o entit√† del database).
> 

---

### Caratteristiche chiave

| Caratteristica | Descrizione |
| --- | --- |
| **Senza logica di business** | Sono "contenitori passivi" (POJO in Java, Pydantic/BaseModel in Python), che includono solo dati e metodi di accesso (`getter/setter`). |
| **Selezione dei campi** | Contengono solo i campi **necessari per la comunicazione**, riducendo il payload. |
| **Serializzabili** | Possono essere facilmente **serializzati/deserializzati** (JSON, XML, etc.) per viaggiare attraverso la rete. |
| **Disaccoppiano** | Separano **modelli interni** e rappresentazioni esterne (API), garantendo maggiore **flessibilit√† e sicurezza**. |

In un sistema distribuito (es. microservizi, SOA), i moduli comunicano attraverso la rete. In questo contesto, i DTO svolgono ruoli fondamentali:

***Astrazione del modello interno***

I modelli di dominio (entit√†) sono spesso complessi o contengono dati sensibili.

- I DTO fungono da **rappresentazioni semplificate e sicure**.

***Riduzione della quantit√† di dati trasmessi***

I DTO evitano il trasferimento di dati superflui.

Questo riduce:

- Carico sulla rete
- Tempo di serializzazione
- Costi su reti mobili o API pubbliche

***Stabilit√† dell‚Äôinterfaccia***

Le modifiche al modello interno **non influenzano** i consumatori esterni, perch√© l‚Äôinterfaccia pubblica (il DTO) resta stabile.

***Validazione e sicurezza***

I DTO possono essere dotati di **validazione dei campi** (es. Pydantic in Python) e mascherare dati sensibili. Questo migliora la **sicurezza** delle API e la robustezza contro input malformati.

***Facilitano la serializzazione***

Essendo progettati per la trasmissione, i DTO sono facilmente **convertibili in formati standard** (JSON, XML) per la comunicazione tra servizi scritti in linguaggi diversi.

### üîÑ **Mapping: DTO vs Entit√†**

Poich√© i DTO sono separati dalle entit√† di dominio o dal modello dati, √® necessario un **mapping bidirezionale**:

- **Da Entit√† a DTO** ‚Üí per inviare dati in uscita (es. risposte API)
- **Da DTO a Entit√†** ‚Üí per ricevere e validare input (es. creazione/modifica di record)

| Linguaggio | Libreria | Note |
| --- | --- | --- |
| Java | MapStruct | Mapping a tempo di compilazione, veloce e type-safe |
| Java | ModelMapper | Mapping flessibile, a runtime |
| Python | Marshmallow | Serializzazione + validazione |
| Python | Pydantic | Validazione, conversione e auto-documentazione (es. con FastAPI) |

### üß™ **Esempio Pratico (Java)**

```java
// Entit√†
public class UserEntity {
    private Long id;
    private String username;
    private String passwordHash;
    private Date createdAt;
}

// DTO
public class UserDTO {
    private String username;
}

```

‚û°Ô∏è Espone solo `username`, **nascondendo la password** e altri dati interni

---

## 11) Perch√© Spring Cloud Stream fornisce un livello di astrazione rispetto all‚Äôuso diretto delle librerie native dei broker?

Spring Cloud Stream √® progettato per semplificare lo sviluppo di applicazioni basate su messaggistica asincrona, offrendo un **livello di astrazione** che nasconde le complessit√† specifiche di ciascun sistema di messaggistica (come Kafka, RabbitMQ, Amazon Kinesis, ecc.). Questo livello di astrazione si traduce in:

1. **Portabilit√† e indipendenza dalla tecnologia sottostante:**
    
    Gli sviluppatori scrivono il codice utilizzando API e concetti comuni (binding, channels, sources, sinks) senza dover conoscere le API specifiche del broker. Se si decide di cambiare broker, baster√† modificare la configurazione senza toccare il codice applicativo.
    
2. **Semplificazione dello sviluppo:**
    
    La gestione delle connessioni, serializzazione, error handling, partizionamento e bilanciamento del carico sono gestiti automaticamente dal framework, riducendo la quantit√† di codice boilerplate e i potenziali errori.
    
3. **Supporto a pattern comuni e best practice:**
    
    Spring Cloud Stream incorpora nativamente pattern di messaging come pub-sub, consumer groups, gestione dei gruppi di consumatori, partizionamento, retry automatici, circuit breaker e altre funzionalit√† avanzate, che altrimenti richiederebbero implementazioni manuali.
    

### Vantaggi dell‚Äôastrazione rispetto all‚Äôuso diretto delle librerie native:

- **Maggiore velocit√† di sviluppo** e manutenzione pi√π semplice.
- **Flessibilit√†:** possibilit√† di cambiare broker senza riscrivere il codice.
- **Uniformit√†:** si usa un modello standard indipendente dal provider.

### Trade-off e limiti:

- **Minor controllo sui dettagli pi√π specifici e avanzati** di ciascun broker (es. configurazioni custom o ottimizzazioni di basso livello).
- **Overhead di astrazione:** una leggera perdita in performance e configurabilit√† fine.
- **Possibili ritardi nel supporto delle nuove funzionalit√†** specifiche del broker finch√© non vengono integrate in Spring Cloud Stream.
- **Dipendenza da un framework esterno**, che richiede aggiornamenti e attenzione alle versioni.

Spring Cloud Stream √® ideale per chi vuole **scrivere codice pulito, modulare e facilmente mantenibile**, senza dover conoscere i dettagli di ogni broker di messaggistica. Offre un bilanciamento ottimale tra facilit√† d‚Äôuso e potenza, ma chi ha necessit√† di funzionalit√† molto specifiche o ottimizzazioni avanzate pu√≤ valutare l‚Äôuso diretto delle librerie native.
